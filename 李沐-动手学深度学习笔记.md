# 李沐-动手学深度学习笔记

参考课程：B站up主：跟李沐学AI——动手学深度学习v2

参考教材：《动手学深度学习》

## 00、预告

学习深度学习关键是<font color='orange'>动手</font>

- 深度学习是人工智能最热的领域
- 核心是神经网络
- 神经网络是一门语言
- 应该像学习Python/C++一样学习深度学习

神经网络是非常灵活的框架

《动手学深度学习》内容免费：https://zh.d2l.ai/

中文版v1

- 网页浏览：https://zh.d2l.ai/
- 源代码Github地址：https://github.com/d2l-ai/d2l-zh

动手学深度学习v2

- 针对数据科学家、工程师和在校学生
  - 只需要最基础的数学和Python编程
- 讲述算法、实现，在线答疑，课内比赛
  - 使用Pytorch代码实现
- https://courses.d2l.ai/zh-v2

## 01、课程安排

**目标**

- 介绍深度学习经典和最新模型
  - LeNet, ResNet, LSTM, BERT, ...
- 机器学习基础
  - 损失函数、目标函数、过拟合、优化
- 实践
  - 使用Pytorch实现介绍的知识点
  - 在真实数据上体验算法效果

**内容**

- 深度学习基础 —— 线性神经网络，多层感知机
- 卷积神经网络 —— LeNet, AlexNet, VGG, Inception, ResNet
- 循环神经网络 —— RNN, GRU, LSTM, seq2seq
- 注意力机制 —— Attention, Transformer
- 优化算法 —— SGD, Momentum, Adam
- 高性能计算 —— 并行，多GPU，分布式
- 计算机视觉 —— 目标检测，语义分割
- 自然语言处理 —— 词嵌入，BERT

**你将学到什么**

- What：深度学习里有哪些技术
- How：如何实现和调参
- Why：背后的原因（直觉、数学）

**资源**

- 课程主页：https://courses.d2l.ai/zh-v2
- 教材：https://zh-v2.d2l.ai/
- 课程论坛讨论：https://discuss.d2l.ai/c/16
- Pytorch论坛：https://discuss.pytorch.org/

## 02、深度学习介绍

自然语言处理、计算机视觉、深度学习

- 横向：符号学、概率模型、机器学习

- 纵向：感知、推理、知识、规划

模型的可解释性（黑盒，为什么有效/无效，在什么地方有偏差）、模型的有效性

## 03、安装

学习效果：看书 < 听课 < 看+听 < 看+听+动手实操 < 竞赛 < 讲课

本地安装

- [可选] 使用 conda/miniconda 环境
- 安装需要的包
- 下载代码并执行

#### Windows下安装CUDA和Pytorch跑深度学习

使用清华源进行安装下载，速度更快（国内环境）；将下行命令中的packages替换成要安装的包即可

```shell
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple packages
```

参考视频：【Windows 下安装 CUDA 和 Pytorch 跑深度学习 - 动手学深度学习v2】 https://www.bilibili.com/video/BV18K411w7Vs/?share_source=copy_web&vd_source=769ad23db0f196e2d0701d2edd5e74a2

1. 确认有Nvidia GPU
   - Win+R：dxdiag查看GPU（显示选项卡）；如果没有Nvidia GPU，是集成显卡或者AMD的GPU的话基本上不行

2. 安装CUDA

   - CUDA：https://developer.nvidia.com/cuda-downloads

   - 命令行输入：`nvidia-smi` 验证是否安装成功

3. 安装miniconda

   - 地址：https://docs.conda.io/en/latest/miniconda.html

   - 在conda的shell中查看python版本：`python --version`

4. 安装GPU版PyTorch

   - 地址：https://pytorch.org/get-started/locally/


   - 选择完成后复制安装命令在conda的shell中安装

   - ```shell
     python
     >>> import torch
     >>> a = torch.ones((3,1))
     >>> a = a.cuda(0)
     >>> b = torch.ones((3,1)).cuda(0)
     >>> a + b
     tensor([[2.],
             [2.],
             [2.]], device='cuda:0')
     ```

5. 安装d2l和Jupyter

   - `pip install jupyter d2l`因为网速报错一片红（这一步游到海峡对面会比较快(不是)）

   - `pip install -i https://pypi.tuna.tsinghua.edu.cn/simple jupyter d2l`使用镜像下载

6. 下载d2l记事本运行测试

   - https://zh-v2.d2l.ai/ —— Jupyter记事本 —— 下载完成后解压
   - 通过`cd`命令到解压后的目录下
   - `jupyter notebook`命令打开jupyter

#### 安装d2l出现问题-参考文章：

https://blog.csdn.net/weixin_47603087/article/details/129516847
https://blog.csdn.net/wzk4869/article/details/127795541
https://blog.csdn.net/Leolanck/article/details/131768888

#### 安装d2l报错后解决方案：

（具体问题具体分析，仅供参考）

```shell
# 尝试更新conda环境
conda  update  --all

# 清除conda未使用的软件包缓存
conda  clean --all
```

准备工作：

- 使用环境：anaconda3

- 下载whl ：https://www.cnpython.com/pypi/d2l/dl-d2l-0.15.1-py3-none-any.whl

- 正式配环境：把下载好的文件[d2l-0.15.1-py3-none-any.whl](https://www.cnpython.com/pypi/d2l/dl-d2l-0.15.1-py3-none-any.whl)放到conda的miniconda3\envs\PyTorch路径下（路径自定义）

- cd 到本地d2l的文件目录

- d2l包安装时会需要安装很多其他的包，比如pandas,numpy，把这些安装容易卡住的包单独提前安装好

  ```shell
  pip install pandas
  
  pip install matplotlib
  
  pip install jupyter
  
  pip install numpy
  ```

- 最后再安装d2l，使用下列命令进行安装

  ```shell
  pip install d2l-0.15.1-py3-none-any.whl
  ```

- 检验是否安装成功，运行下列命令

  ```shell
  conda list
  ```

## 04、数据操作 + 数据预处理

#### 数据操作

𝑛维数组，也称为*张量*（tensor）；张量表示一个由数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的*向量*（vector）； 具有两个轴的张量对应数学上的*矩阵*（matrix）； 具有两个轴以上的张量没有特殊的数学名称。

张量做运算时，如果维数不同，会调用广播机制（broadcasting mechanism）来执行按元素操作，将不同维数复制成同样的维数再做运算

如果在后续计算中没有重复使用`X`（某个变量或者说张量）， 我们也可以使用`X[:] = X + Y`或`X += Y`来减少操作的内存开销。（使其原地执行这些更新，不分配新的内容空间和地址）

torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。即torch的tensor和Numpy的ndarray共享内存

总结：深度学习存储和操作数据的主要接口是张量（𝑛维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象。

#### 数据预处理

在Python中常用的数据分析工具中，我们通常使用`pandas`软件包。 像庞大的Python生态系统中的许多其他扩展包一样，`pandas`可以与张量兼容。

读取csv文件一般使用pandas库

一般需要处理缺失的数据，典型的方法包括 插值 和 删除

numpy大大提升了python中数据计算的速度，numpy更加核心的问题是将问题向量化、并行化的思路

小结：

- `pandas`软件包是Python中常用的数据分析工具中，`pandas`可以与张量兼容。
- 用`pandas`处理缺失的数据时，我们可根据情况选择用插值法和删除法。

【一个10分钟的numpy入门教程】 https://www.bilibili.com/video/BV1Wy4y1h7ii/?share_source=copy_web&vd_source=769ad23db0f196e2d0701d2edd5e74a2

## 05、线性代数

矩阵按元素乘法为 哈达玛积（Hadamard product）

按特定轴求和：axis=0就去掉shape的第1个维度（索引为0）；按照某一个维度求和，等价于shape把哪一个维度去掉，如果keepdims=True就不会去掉该维度，而是该维度变成1

矩阵的 弗罗贝尼乌斯范数（Frobenius norm）是矩阵元素的平方和的平方根

L~1~范数，它表示为向量元素的绝对值之和

L~2~范数是向量元素平方和的平方根

## 06、矩阵计算

矩阵计算讲矩阵怎么求导数

导数是切线的斜率

亚导数：将导数拓展到不可微的函数

梯度：将导数拓展到向量；梯度跟等高线正交，梯度一定指向值变化最大的方向

matrix（矩阵，复数matrices）

## 07、自动求导

identity matrix是单位矩阵，是一个n*n的方阵，对角线对1，其他元素都为0

## 08、线性回归 + 基础优化算发

标量由只有一个元素的张量表示

向量可以被视为标量值组成的列表。 这些标量值被称为向量的*元素*（element）或*分量*（component）

平方损失：1/2（真实值-估计值）^2^

基础优化算法，最常见的是 梯度下降



使用平方损失和绝对差值都可以

## 09、Softmax 回归 + 损失函数 + 图片分类数据集

Softmax回归 本质是一个分类问题

回归 vs 分类

- 回归估计一个连续值
- 分类预测一个离散类别

回归

- 单连续值输出
- 自然区间R
- 跟真实值的区别作为损失

分类

- 通常多个输出
- 输出i是预测为第i类的置信度



损失函数用来衡量预测值和真实值之间的区别

均方损失：L2 Loss

绝对值损失：L1 Loss

## 10、多层感知机+代码实现

**感知机**

感知机做二分类问题（1或-1），是最早的AI模型之一

求解算法等价于使用批量大小为1的梯度下降

感知机不能拟合XOR函数，它只能产生线性分割面

**多层感知机**

多层感知机使用隐藏层和激活函数来得到非线性模型

常用激活函数是Sigmoid，Tanh，ReLU

使用Softmax来处理多类分类

超参数为隐藏层数，和各个隐藏层大小

## 11、模型选择+过拟合和欠拟合

**模型选择**

**训练误差和泛化误差**

训练误差：模型在训练数据上的误差

泛化误差：模型在新数据上的误差

例子：根据模考成绩来预测未来的考试分数，在过去的考试中表现很好（训练误差）不代表未来考试一定会好（泛化误差）

**验证数据集和测试数据集**

验证数据集：一个用来评估模型好坏的数据集

- 例如拿出50%的训练数据
- 不要跟训练数据混在一起（常犯错误）

测试数据集：只用一次的数据集。例如 

- 未来的考试
- 我出价的房子的实际成交价
- 用在Kaggle私有排行榜中的数据集

**K-则交叉验证**

- 在没有足够多数据时使用（常态）

- 算法：将训练数据分割成K块，For i = 1,...,K 使用第i块作为验证数据集，其余作为训练数据集；报告K个验证集误差的平均
- 常用：K= 5 或 10（做5次或者10次训练，K是训练次数）

**总结**

训练数据集：训练模型参数

验证数据集：选择模型超参数

非数据集上通常使用k-折交叉验证



**过拟合和欠拟合**

Overfitting和Underfitting

模型容量

- 拟合各种函数的能力
- 低容量的模型难以拟合训练数据
- 高容量的模型可以记住所有的训练数据

并不是模型容量越大，训练误差越低就越好；还要关注泛化误差，以及泛化误差和训练误差之间的间隔

深度学习核心：模型容量足够大，在足够大的情况下，通过各种手段来控制模型容量，得到泛化误差往下降



估计模型容量（控制模型复杂度）

给定一个模型种类，将有两个主要因素

- 参数的个数
- 参数值的选择范围



VC维（深度学习中很少用，因为衡量不是很准确以及计算深度学习模型的VC维很困难）

- 统计学习理论的一个核心思想
- 对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型来对它进行完美分类



**数据复杂度**

多个重要因素

- 样本个数
- 每个样本的元素个数
- 时间、空间结构
- 多样性



**总结**

模型容量需要匹配数据复杂度，否则可能导致欠拟合和过拟合

统计机器学习提供数学工具来衡量模型复杂度

实际中一般靠观察训练误差和验证误差







